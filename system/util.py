from string import Template
from symusic import Score, Synthesizer
from transformers import BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM, PreTrainedModel, PreTrainedTokenizer
import os
import re
import torch
import torchaudio

PROMPT_VAD = Template(
    "You are given 3 values, which represent valence, arousal, and dominance respectively. The values are on " +\
    "a scale of 1 to 5, with 1 being the lowest. Output an appropriate chord progression, tempo, and scale that " +\
    "corresponds to the emotion represented by these values." +\
    "Values: ${valence}, ${arousal}, ${dominance}\n"
) 
PROMPT_STR = Template(
    "You are given a list of emotions as input. Output an appropriate chord progression, tempo, and scale that " +\
    "corresponds to these emotions." +\
    "Emotions: ${emotions}\n"
)
PROMPT_GEN = Template(
    "You are given a set of rules that a musical piece must follow. Using these rules, compose a musical piece " +\
    "that adheres to the rules.\n" +\
    "${rules}"
)

DEFAULT_PATH = os.path.join(os.getcwd(), "artifacts", "music")

def construct_music(generated_music : str, name : str, base_path : str = DEFAULT_PATH) -> str:
    """
    Takes the music piece generated by the model and converts it into an audio file
    Code retrieved from: https://huggingface.co/m-a-p/ChatMusician
    """
    abc_pattern = r'(X:\d+\n(?:[^\n]*\n)+)'
    abc_notation = re.findall(abc_pattern, generated_music +'\n')[0]
    s = Score.from_abc(abc_notation)
    audio = Synthesizer().render(s, stereo=True)
    song_path = os.path.join(base_path, f"{name}.wav")
    torchaudio.save(song_path, torch.FloatTensor(audio), 44100)
    return song_path


def save_lora_checkpoint(model, path: str):
    """
    Save all LoRA adapter weights only for the trained adapter model.
    """
    state_dict = model.state_dict()
    for key in list(state_dict.keys()):
        if "lora" not in key:
            state_dict.pop(key)
    torch.save(state_dict, path)


def load_from_lora_checkpoint(model, path: str, device: torch.device):
    """
    Load LoRA weights from the checkpoint into the model.
    """
    state_dict = torch.load(path, map_location=device)
    assert isinstance(state_dict, dict)
    model.load_state_dict(state_dict, strict=False)
    return model

def load_chatmusician_from_pretrained() -> PreTrainedModel:
    """
    Loads and quantizes the ChatMusician model.
    """
    bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    )
    model = AutoModelForCausalLM.from_pretrained(
        "m-a-p/ChatMusician",
        quantization_config=bnb_config,
        trust_remote_code=True,
        device_map="auto",
        resume_download=True
    )

    return model

def load_chatmusician_tokenizer() -> PreTrainedTokenizer:
    tokenizer = AutoTokenizer.from_pretrained(
        "m-a-p/ChatMusician",
        trust_remote_code=True
    )
    return tokenizer